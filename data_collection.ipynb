{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting fake_useragent\n",
      "  Using cached fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Using cached numpy-2.0.1-cp311-cp311-macosx_11_0_arm64.whl (13.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, fake_useragent, urllib3, tzdata, soupsieve, numpy, idna, et-xmlfile, charset-normalizer, certifi, requests, pandas, openpyxl, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.7.4 charset-normalizer-3.3.2 et-xmlfile-1.1.0 fake_useragent-1.5.1 idna-3.7 numpy-2.0.1 openpyxl-3.1.5 pandas-2.2.2 pytz-2024.1 requests-2.32.3 soupsieve-2.5 tzdata-2024.1 urllib3-2.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 fake_useragent pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import urllib.parse\n",
    "\n",
    "def google_search(query, num_results, time_filter = None):\n",
    "    ua = UserAgent()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "\n",
    "    google_url = f\"https://www.google.com/search?q={query}&num={num_results}\"\n",
    "\n",
    "    if time_filter:\n",
    "        google_url += f\"&tbs={time_filter}\"\n",
    "\n",
    "    response = requests.get(google_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        search_results = []\n",
    "\n",
    "        for g in soup.find_all('div', class_='g'):\n",
    "            anchors = g.find_all('a')\n",
    "            if anchors:\n",
    "                link = anchors[0]['href']\n",
    "                search_results.append(link)\n",
    "                \n",
    "        return search_results\n",
    "    else:\n",
    "        print(f\"failed to retrieve search results: status code {response.status_code}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quarters(start_year, end_year):\n",
    "    quarters = {}\n",
    "    if end_year == 2024:\n",
    "        quarters[\"2024 Q1\"] = \"cdr:1,cd_min:1/1/2024,cd_max:3/31/2024\"\n",
    "        quarters[\"2024 Q2\"] = \"cdr:1,cd_min:4/1/2024,cd_max:6/30/2024\"\n",
    "        end_year -= 1\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        quarters[f\"{year} Q1\"] = f\"cdr:1,cd_min:1/1/{year},cd_max:3/31/{year}\"\n",
    "        quarters[f\"{year} Q2\"] = f\"cdr:1,cd_min:4/1/{year},cd_max:6/30/{year}\"\n",
    "        quarters[f\"{year} Q3\"] = f\"cdr:1,cd_min:7/1/{year},cd_max:9/30/{year}\"\n",
    "        quarters[f\"{year} Q4\"] = f\"cdr:1,cd_min:10/1/{year},cd_max:12/31/{year}\"\n",
    "    return quarters\n",
    "\n",
    "def generate_query(source_list):\n",
    "    dictionary = {}\n",
    "    for source in source_list:\n",
    "        if source in dictionary:\n",
    "            continue\n",
    "        else:\n",
    "            dictionary[source] = f\"singapore industrial property market {source}\"\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  URLs  \\\n",
      "0    https://www.channelnewsasia.com/singapore/mark...   \n",
      "1          https://www.youtube.com/watch?v=JsMbvmY9FWA   \n",
      "2    https://www.channelnewsasia.com/singapore/joho...   \n",
      "3          https://www.youtube.com/watch?v=iJ2Xfc0xnZk   \n",
      "4    https://m.facebook.com/ChannelNewsAsia/posts/8...   \n",
      "..                                                 ...   \n",
      "432  https://plbinsights.com/the-rise-of-self-stora...   \n",
      "433  https://www.propertyguru.com.sg/property-guide...   \n",
      "434  https://sbr.com.sg/commercial-property/in-focu...   \n",
      "435  https://realestateasia.com/videos/proptech-kuc...   \n",
      "436  https://cosysingapore.com/commercial-property-...   \n",
      "\n",
      "                        Source  Quarter  \n",
      "0                          cna  2024 Q1  \n",
      "1                          cna  2024 Q1  \n",
      "2                          cna  2024 Q1  \n",
      "3                          cna  2024 Q1  \n",
      "4                          cna  2024 Q1  \n",
      "..                         ...      ...  \n",
      "432  singapore business review  2023 Q3  \n",
      "433  singapore business review  2023 Q3  \n",
      "434  singapore business review  2023 Q3  \n",
      "435  singapore business review  2023 Q3  \n",
      "436  singapore business review  2023 Q3  \n",
      "\n",
      "[437 rows x 3 columns]\n",
      "                                                   URLs    Source  Quarter\n",
      "0     https://www.channelnewsasia.com/singapore/mark...       cna  2024 Q1\n",
      "1           https://www.youtube.com/watch?v=JsMbvmY9FWA       cna  2024 Q1\n",
      "2     https://www.channelnewsasia.com/singapore/joho...       cna  2024 Q1\n",
      "3           https://www.youtube.com/watch?v=iJ2Xfc0xnZk       cna  2024 Q1\n",
      "4     https://m.facebook.com/ChannelNewsAsia/posts/8...       cna  2024 Q1\n",
      "...                                                 ...       ...      ...\n",
      "1180  https://www.edgeprop.sg/industrial/kewalram-house  edgeprop  2022 Q4\n",
      "1181     https://asianprimeproperties.sg/property-news/  edgeprop  2022 Q4\n",
      "1182  https://www.theedgesingapore.com/billion-dolla...  edgeprop  2022 Q4\n",
      "1183  https://static1.squarespace.com/static/5909917...  edgeprop  2022 Q4\n",
      "1184  https://www.propertyguru.com.sg/agent/sharon-k...  edgeprop  2022 Q4\n",
      "\n",
      "[1185 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_dictionary = generate_query([\"cna\", \"singapore business review\"])\n",
    "\n",
    "quarter_dictionary = generate_quarters(2020, 2024)\n",
    "\n",
    "headers = [\"URLs\", \"Source\", \"Quarter\"]\n",
    "df = pd.DataFrame(columns=headers)\n",
    "\n",
    "for source, query in query_dictionary.items():\n",
    "    for quarter, time_filter in quarter_dictionary.items():\n",
    "        results = google_search(query, num_results=20, time_filter=time_filter)\n",
    "        temp_df = pd.DataFrame({\"URLs\": results, \"Source\": source, \"Quarter\": quarter})\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "query_dictionary = generate_query([\"straits times\", \"business times\", \"edgeprop\"])\n",
    "\n",
    "quarter_dictionary = generate_quarters(2020, 2024)\n",
    "\n",
    "for source, query in query_dictionary.items():\n",
    "    for quarter, time_filter in quarter_dictionary.items():\n",
    "        results = google_search(query, num_results=30, time_filter=time_filter)\n",
    "        temp_df = pd.DataFrame({\"URLs\": results, \"Source\": source, \"Quarter\": quarter})\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_excel(\"urls.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"urls.xlsx\")\n",
    "duplicates = df[\"URLs\"].duplicated(keep=False)\n",
    "df = df[~duplicates]\n",
    "\n",
    "with pd.ExcelWriter(\"urls.xlsx\", engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    df.to_excel(writer, sheet_name=\"2020 - 2024\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
