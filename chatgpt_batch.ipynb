{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating JSONL File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Analyze the market sentiments on Singapore's industrial market. Rate it from -1 to 1 on the sentiments for Singapore's industrial market. Only give me the value.\",\n",
    "        \"Analyse the market sentiments on Singapore's industrial market. Rate it either positive, neutral or negative for the sentiments for Singapore's industrial market, whether the text is indicating a positive, neutral or negative outlook. Only give me the value.\",\n",
    "        \"For the inputted text, analyse the market sentiments on Singapore's industrial market. Rate it between -1 to 1, whether the text is suggesting a boom or bust in the industrial properties market. Only give me the value.\",\n",
    "        \"For the inputted text, analyse the market sentiments on Singapore's industrial market. Rate it either positive, neutral or negative for the sentiments for Singapore's industrial market. Only give me the value.\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# read the Excel file\n",
    "excel_file = 'texts_cleaned.xlsx'\n",
    "sheet_name = '2010 - 2014'\n",
    "df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "\n",
    "# prepare the output JSONL file\n",
    "output_file = '2010_2014(4).jsonl'\n",
    "\n",
    "# define fixed values\n",
    "model = \"gpt-4o-mini\"\n",
    "system_content = \"For the inputted text, analyse the market sentiments on Singapore's industrial market. Rate it either positive, neutral or negative for the sentiments for Singapore's industrial market. Only give me the value.\"\n",
    "url_template = \"/v1/chat/completions\"\n",
    "method = \"POST\"\n",
    "\n",
    "# open the file for writing\n",
    "with open(output_file, 'w') as file:\n",
    "    for index, row in df.iterrows():\n",
    "        # generate custom_id\n",
    "        custom_id = f\"request-{index + 1}\"\n",
    "        \n",
    "        # extract the 'text' column for user content\n",
    "        user_content = row['Text']\n",
    "        \n",
    "        # create the JSON structure\n",
    "        json_line = {\n",
    "            \"custom_id\": custom_id,\n",
    "            \"method\": method,\n",
    "            \"url\": url_template,\n",
    "            \"body\": {\n",
    "                \"model\": model,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_content},\n",
    "                    {\"role\": \"user\", \"content\": user_content}\n",
    "                ],\n",
    "                \"max_tokens\": 10\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # write the JSON line to the file\n",
    "        file.write(json.dumps(json_line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m   file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2010_2014(4).jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m   purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Visual Code Studio/jtc-market-sentiments/env/lib/python3.11/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"2010_2014(4).jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_RegEVUfEjx3JB7yfQmdlhyo1', completion_window='24h', created_at=1723011991, endpoint='/v1/chat/completions', input_file_id='file-ltad2Vw6Sk0apkK3nLmz7GLp', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1723098391, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.create(\n",
    "  input_file_id=\"file-ltad2Vw6Sk0apkK3nLmz7GLp\",\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_0qnU69dwioIxCL3nNUgc3F3Z', completion_window='24h', created_at=1723011380, endpoint='/v1/chat/completions', input_file_id='file-sKALRTzPcowTdKboQFo42suU', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1723011395, error_file_id=None, errors=None, expired_at=None, expires_at=1723097780, failed_at=None, finalizing_at=1723011392, in_progress_at=1723011380, metadata=None, output_file_id='file-bZW75DXg20MxRq5yBHJZ9D3G', request_counts=BatchRequestCounts(completed=78, failed=0, total=78))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_0qnU69dwioIxCL3nNUgc3F3Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSONL to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "input_file = './chatgpt/2010_2014/batch_0qnU69dwioIxCL3nNUgc3F3Z_output.jsonl'\n",
    "with open(input_file, 'r') as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line)\n",
    "        extracted_data = {\n",
    "            'custom_id': record['custom_id'],\n",
    "            'message_content': record['response']['body']['choices'][0]['message']['content']\n",
    "        }\n",
    "        data.append(extracted_data)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "output_file = 'sentiments.xlsx'\n",
    "sheet_name = '2010 - 2014'\n",
    "df.to_excel(output_file, sheet_name= sheet_name, index=False)\n",
    "# with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    # df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining More JSONL File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            extracted_data = {\n",
    "                'custom_id': record['custom_id'],\n",
    "                'message_content': record['response']['body']['choices'][0]['message']['content']\n",
    "            }\n",
    "            data.append(extracted_data)\n",
    "    return data\n",
    "\n",
    "existing_file = 'sentiments.xlsx'\n",
    "sheet_name = '2010 - 2014'\n",
    "existing_df = pd.read_excel(existing_file, sheet_name=sheet_name)\n",
    "\n",
    "new_jsonl_file = './chatgpt/2010_2014/batch_RegEVUfEjx3JB7yfQmdlhyo1_output.jsonl'\n",
    "new_data = extract_data_from_jsonl(new_jsonl_file)\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "merged_df = existing_df.merge(new_df, on='custom_id', how='left', suffixes=(None, '_z'))\n",
    "\n",
    "with pd.ExcelWriter(existing_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    merged_df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
